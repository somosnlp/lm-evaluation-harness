{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fake_news_es (noticia) DONE -> create hf dataset\n",
    "- emoevent DONE\n",
    "- crows_pairs_spanish DONE\n",
    "\n",
    "opcional\n",
    "- parafrases_sushi (paws_es) REVIEW COL NAMES -> create hf dataset\n",
    "- offendes EXPLICAR OPCIONES\n",
    "- offendes spans? NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EmoEvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'event', 'tweet', 'offensive', 'emotion'],\n",
      "        num_rows: 10835\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'event', 'tweet', 'offensive', 'emotion'],\n",
      "        num_rows: 1588\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'event', 'tweet', 'offensive', 'emotion'],\n",
      "        num_rows: 3103\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"SINAI/EmoEvent\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               id            event  \\\n",
      "0  3PA41K45VNA3R7O5I4800HXZBINP7D  ChampionsLeague   \n",
      "1  34R3P23QHS7Q45RI7Z87JOUPIIKWHF  ChampionsLeague   \n",
      "2  3BS6ERDL93DBYA7AULCDU9GE2OZ6DG    GretaThunberg   \n",
      "\n",
      "                                               tweet offensive  emotion  \n",
      "0  Organization looks good. The Barcelona goal wa...        NO   others  \n",
      "1  Fair play from the Dog with a goal celebration...        NO  disgust  \n",
      "2  Well done USER for promoting this important me...        NO      joy  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset[\"test\"])\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['others' 'disgust' 'joy' 'fear' 'surprise' 'sadness' 'anger']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"emotion\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OffendES\n",
    "\n",
    "- Offensive, the target is a person (OFP). Offensive text targeting a specific individual.\n",
    "- Offensive, the target is a group of people or collective (OFG). Offensive text targeting a group of people belonging to the same ethnic group, gender or sexual orientation, political ideology, religious belief, or other common characteristics.\n",
    "- Non-offensive, but with expletive language (NOE). A text that contains rude words, blasphemes, or swearwords but without the aim of offending, and usually with a positive connotation.\n",
    "- Non-offensive (NO). Text that is neither offensive nor contains expletive language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 5.20k/5.20k [00:00<00:00, 7.38MB/s]\n",
      "Downloading data: 100%|██████████| 3.51M/3.51M [00:02<00:00, 1.53MB/s]\n",
      "Downloading data: 100%|██████████| 22.5k/22.5k [00:00<00:00, 99.1kB/s]\n",
      "Downloading data: 100%|██████████| 2.84M/2.84M [00:01<00:00, 1.89MB/s]\n",
      "Generating train split: 100%|██████████| 16710/16710 [00:00<00:00, 154551.91 examples/s]\n",
      "Generating validation split: 100%|██████████| 100/100 [00:00<00:00, 29610.34 examples/s]\n",
      "Generating test split: 100%|██████████| 13606/13606 [00:00<00:00, 201075.00 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['comment_id', 'comment', 'influencer', 'influencer_gender', 'media', 'label'],\n",
      "        num_rows: 16710\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['comment_id', 'comment', 'influencer', 'influencer_gender', 'media', 'label'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['comment_id', 'comment', 'influencer', 'influencer_gender', 'media', 'label'],\n",
      "        num_rows: 13606\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "offendes = load_dataset(\"SINAI/OffendES\")\n",
    "print(offendes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   comment_id                         comment influencer influencer_gender  \\\n",
      "0       54745                 Lacasito moreno   wismichu               man   \n",
      "1        5595  Yo pensaba que celopan era gay      miare             woman   \n",
      "2       53477                 la bruja del 77      miare             woman   \n",
      "\n",
      "       media label  \n",
      "0  instagram    NO  \n",
      "1    youtube    NO  \n",
      "2  instagram    NO  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(offendes[\"test\"])\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NO' 'OFP' 'NOE' 'OFG']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrowsPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for crows_pairs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/crows_pairs\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['id', 'sent_more', 'sent_less', 'stereo_antistereo', 'bias_type', 'annotations', 'anon_writer', 'anon_annotators'],\n",
      "        num_rows: 1508\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "cp = load_dataset(\"crows_pairs\")\n",
    "print(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cp[\"test\"])\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parafrases Sushi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for GIL-UNAM/SpanishParaphraseCorpora contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/GIL-UNAM/SpanishParaphraseCorpora\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 5.08k/5.08k [00:00<00:00, 11.2MB/s]\n",
      "Downloading readme: 100%|██████████| 2.55k/2.55k [00:00<00:00, 2.32MB/s]\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to expression here. Maybe you meant '==' instead of '='? (SpanishParaphraseCorpora.py, line 86)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[15], line 1\u001b[0m\n    para = load_dataset(\"GIL-UNAM/SpanishParaphraseCorpora\")\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages/datasets/load.py:2587\u001b[0m in \u001b[1;35mload_dataset\u001b[0m\n    builder_instance = load_dataset_builder(\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages/datasets/load.py:2294\u001b[0m in \u001b[1;35mload_dataset_builder\u001b[0m\n    builder_cls = get_dataset_builder_class(dataset_module, dataset_name=dataset_name)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages/datasets/load.py:251\u001b[0m in \u001b[1;35mget_dataset_builder_class\u001b[0m\n    builder_cls = import_main_class(dataset_module.module_path)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages/datasets/load.py:166\u001b[0m in \u001b[1;35mimport_main_class\u001b[0m\n    module = importlib.import_module(module_path)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126\u001b[0m in \u001b[1;35mimport_module\u001b[0m\n    return _bootstrap._gcd_import(name[level:], package, level)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m in \u001b[1;35m_gcd_import\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m in \u001b[1;35m_find_and_load\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m in \u001b[1;35m_find_and_load_unlocked\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m in \u001b[1;35m_load_unlocked\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m in \u001b[1;35mexec_module\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap_external>:1074\u001b[0m in \u001b[1;35mget_code\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap_external>:1004\u001b[0m in \u001b[1;35msource_to_code\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0;36m in \u001b[0;35m_call_with_frames_removed\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/.cache/huggingface/modules/datasets_modules/datasets/GIL-UNAM--SpanishParaphraseCorpora/d572753fa89195ea40fd2be4ec62abc52b6c9f57cfc1d0511b5bcb17961bcbc9/SpanishParaphraseCorpora.py:86\u001b[0;36m\u001b[0m\n\u001b[0;31m    paraphrased_samples, non-paraphrased_samples = None, None\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to expression here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "para = load_dataset(\"GIL-UNAM/SpanishParaphraseCorpora\")\n",
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
