{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (2.19.1)\n",
      "Requirement already satisfied: filelock in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from datasets) (3.14.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from datasets) (16.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.3.1,>=2023.1.0 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from datasets) (0.23.0)\n",
      "Requirement already satisfied: packaging in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from datasets) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EmoEvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'event', 'tweet', 'offensive', 'emotion'],\n",
      "        num_rows: 10835\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'event', 'tweet', 'offensive', 'emotion'],\n",
      "        num_rows: 1588\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'event', 'tweet', 'offensive', 'emotion'],\n",
      "        num_rows: 3103\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"SINAI/EmoEvent\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               id            event  \\\n",
      "0  3PA41K45VNA3R7O5I4800HXZBINP7D  ChampionsLeague   \n",
      "1  34R3P23QHS7Q45RI7Z87JOUPIIKWHF  ChampionsLeague   \n",
      "2  3BS6ERDL93DBYA7AULCDU9GE2OZ6DG    GretaThunberg   \n",
      "\n",
      "                                               tweet offensive  emotion  \n",
      "0  Organization looks good. The Barcelona goal wa...        NO   others  \n",
      "1  Fair play from the Dog with a goal celebration...        NO  disgust  \n",
      "2  Well done USER for promoting this important me...        NO      joy  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset[\"test\"])\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['others' 'disgust' 'joy' 'fear' 'surprise' 'sadness' 'anger']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"emotion\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrowsPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for crows_pairs contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/crows_pairs\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['id', 'sent_more', 'sent_less', 'stereo_antistereo', 'bias_type', 'annotations', 'anon_writer', 'anon_annotators'],\n",
      "        num_rows: 1508\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "cp = load_dataset(\"crows_pairs\")\n",
    "print(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cp[\"test\"])\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mariagrandury/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages/datasets/load.py:1486: FutureWarning: The repository for GIL-UNAM/SpanishParaphraseCorpora contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/GIL-UNAM/SpanishParaphraseCorpora\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "Downloading builder script: 100%|██████████| 5.08k/5.08k [00:00<00:00, 11.2MB/s]\n",
      "Downloading readme: 100%|██████████| 2.55k/2.55k [00:00<00:00, 2.32MB/s]\n"
     ]
    },
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to expression here. Maybe you meant '==' instead of '='? (SpanishParaphraseCorpora.py, line 86)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m~/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn[15], line 1\u001b[0m\n    para = load_dataset(\"GIL-UNAM/SpanishParaphraseCorpora\")\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages/datasets/load.py:2587\u001b[0m in \u001b[1;35mload_dataset\u001b[0m\n    builder_instance = load_dataset_builder(\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages/datasets/load.py:2294\u001b[0m in \u001b[1;35mload_dataset_builder\u001b[0m\n    builder_cls = get_dataset_builder_class(dataset_module, dataset_name=dataset_name)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages/datasets/load.py:251\u001b[0m in \u001b[1;35mget_dataset_builder_class\u001b[0m\n    builder_cls = import_main_class(dataset_module.module_path)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m~/Projects/somosnlp/lm-evaluation-harness/venv/lib/python3.11/site-packages/datasets/load.py:166\u001b[0m in \u001b[1;35mimport_main_class\u001b[0m\n    module = importlib.import_module(module_path)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/opt/homebrew/Cellar/python@3.11/3.11.6_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/importlib/__init__.py:126\u001b[0m in \u001b[1;35mimport_module\u001b[0m\n    return _bootstrap._gcd_import(name[level:], package, level)\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap>:1204\u001b[0m in \u001b[1;35m_gcd_import\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap>:1176\u001b[0m in \u001b[1;35m_find_and_load\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap>:1147\u001b[0m in \u001b[1;35m_find_and_load_unlocked\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap>:690\u001b[0m in \u001b[1;35m_load_unlocked\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap_external>:936\u001b[0m in \u001b[1;35mexec_module\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap_external>:1074\u001b[0m in \u001b[1;35mget_code\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m<frozen importlib._bootstrap_external>:1004\u001b[0m in \u001b[1;35msource_to_code\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0;36m in \u001b[0;35m_call_with_frames_removed\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m~/.cache/huggingface/modules/datasets_modules/datasets/GIL-UNAM--SpanishParaphraseCorpora/d572753fa89195ea40fd2be4ec62abc52b6c9f57cfc1d0511b5bcb17961bcbc9/SpanishParaphraseCorpora.py:86\u001b[0;36m\u001b[0m\n\u001b[0;31m    paraphrased_samples, non-paraphrased_samples = None, None\u001b[0m\n\u001b[0m                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to expression here. Maybe you meant '==' instead of '='?\n"
     ]
    }
   ],
   "source": [
    "para = load_dataset(\"GIL-UNAM/SpanishParaphraseCorpora\")\n",
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
