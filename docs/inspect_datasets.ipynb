{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fake_news_es (noticia) DONE -> create hf dataset\n",
    "- emoevent DONE\n",
    "- crows_pairs_spanish DONE\n",
    "\n",
    "opcional\n",
    "- parafrases_sushi (paws_es) REVIEW COL NAMES -> create hf dataset\n",
    "- offendes EXPLICAR OPCIONES\n",
    "- offendes spans? NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EmoEvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'event', 'tweet', 'offensive', 'emotion'],\n",
      "        num_rows: 10835\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'event', 'tweet', 'offensive', 'emotion'],\n",
      "        num_rows: 1588\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'event', 'tweet', 'offensive', 'emotion'],\n",
      "        num_rows: 3103\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"SINAI/EmoEvent\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               id            event  \\\n",
      "0  3PA41K45VNA3R7O5I4800HXZBINP7D  ChampionsLeague   \n",
      "1  34R3P23QHS7Q45RI7Z87JOUPIIKWHF  ChampionsLeague   \n",
      "2  3BS6ERDL93DBYA7AULCDU9GE2OZ6DG    GretaThunberg   \n",
      "\n",
      "                                               tweet offensive  emotion  \n",
      "0  Organization looks good. The Barcelona goal wa...        NO   others  \n",
      "1  Fair play from the Dog with a goal celebration...        NO  disgust  \n",
      "2  Well done USER for promoting this important me...        NO      joy  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(dataset[\"test\"])\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['others' 'disgust' 'joy' 'fear' 'surprise' 'sadness' 'anger']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"emotion\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OffendES\n",
    "\n",
    "- Offensive, the target is a person (OFP). Offensive text targeting a specific individual.\n",
    "- Offensive, the target is a group of people or collective (OFG). Offensive text targeting a group of people belonging to the same ethnic group, gender or sexual orientation, political ideology, religious belief, or other common characteristics.\n",
    "- Non-offensive, but with expletive language (NOE). A text that contains rude words, blasphemes, or swearwords but without the aim of offending, and usually with a positive connotation.\n",
    "- Non-offensive (NO). Text that is neither offensive nor contains expletive language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['comment_id', 'comment', 'influencer', 'influencer_gender', 'media', 'label'],\n",
      "        num_rows: 16710\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['comment_id', 'comment', 'influencer', 'influencer_gender', 'media', 'label'],\n",
      "        num_rows: 100\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['comment_id', 'comment', 'influencer', 'influencer_gender', 'media', 'label'],\n",
      "        num_rows: 13606\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "offendes = load_dataset(\"SINAI/OffendES\")\n",
    "print(offendes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   comment_id                         comment influencer influencer_gender  \\\n",
      "0       54745                 Lacasito moreno   wismichu               man   \n",
      "1        5595  Yo pensaba que celopan era gay      miare             woman   \n",
      "2       53477                 la bruja del 77      miare             woman   \n",
      "\n",
      "       media label  \n",
      "0  instagram    NO  \n",
      "1    youtube    NO  \n",
      "2  instagram    NO  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(offendes[\"test\"])\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NO' 'OFP' 'NOE' 'OFG']\n"
     ]
    }
   ],
   "source": [
    "print(df[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 924/924 [00:00<00:00, 2.60MB/s]\n",
      "Downloading data: 100%|██████████| 1.99M/1.99M [00:08<00:00, 244kB/s]\n",
      "Generating test split: 100%|██████████| 572/572 [00:00<00:00, 8992.86 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['ID', 'CATEGORY', 'TOPICS', 'SOURCE', 'HEADLINE', 'TEXT', 'LINK'],\n",
      "        num_rows: 572\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fake_news = load_dataset(\"mariagrandury/fake_news_corpus_spanish\")\n",
    "print(fake_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID  CATEGORY    TOPICS         SOURCE  \\\n",
      "0   1      True  Covid-19  El Economista   \n",
      "1   2     False  Política     El matinal   \n",
      "2   3      True  Política        El País   \n",
      "\n",
      "                                            HEADLINE  \\\n",
      "0                       Covid-19: mentiras que matan   \n",
      "1  El Gobierno podrá acceder a las IPs de los móv...   \n",
      "2  La comunidad musulmana catalana denuncia a Vox...   \n",
      "\n",
      "                                                TEXT  \\\n",
      "0  El control de la Covid-19 no es sólo un tema d...   \n",
      "1  El Gobierno de Pedro Sánchez y Pablo Iglesias ...   \n",
      "2  Las tres federaciones que agrupan al 90% de la...   \n",
      "\n",
      "                                                LINK  \n",
      "0  https://www.eleconomista.com.mx/opinion/Covid-...  \n",
      "1  https://www.elmatinal.com/espana-ultima-hora/e...  \n",
      "2  https://elpais.com/espana/elecciones-catalanas...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(fake_news[\"test\"])\n",
    "print(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrowsPairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 3.14k/3.14k [00:00<00:00, 14.7MB/s]\n",
      "Downloading data: 100%|██████████| 166k/166k [00:00<00:00, 203kB/s]\n",
      "Generating es_AR split: 100%|██████████| 1509/1509 [00:00<00:00, 154600.86 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    es_AR: Dataset({\n",
      "        features: ['sent_more', 'sent_less', 'stereo_antistereo', 'bias_type', 'id'],\n",
      "        num_rows: 1509\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cp = load_dataset(\"multilingual-crows-pairs/multilingual-crows-pairs\")\n",
    "print(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['sent_more', 'sent_less', 'stereo_antistereo', 'bias_type', 'id'],\n",
      "    num_rows: 1509\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "cp = load_dataset(\"multilingual-crows-pairs/multilingual-crows-pairs\", split=\"es_AR\")\n",
    "print(cp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parafrases Sushi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 819/819 [00:00<00:00, 8.81MB/s]\n",
      "Downloading data: 100%|██████████| 2.18M/2.18M [00:01<00:00, 1.17MB/s]\n",
      "Generating train split: 100%|██████████| 6896/6896 [00:00<00:00, 87359.69 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 6896\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "para = load_dataset(\"mariagrandury/parafrases-sushi\")\n",
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text\n",
      "0  El pescado es un alimento perecedero, es por e...\n",
      "1  El pescado es un alimento perecedero, es por e...\n",
      "2  El pescado es un alimento perecedero, es por e...\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(para[\"train\"])\n",
    "print(df.head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
